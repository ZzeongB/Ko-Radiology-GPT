# ğŸš‘ğŸ¥â˜¢ï¸ Ko-Radiology-GPT â˜¢ï¸ğŸ¥ğŸš‘
### Real-time Q&A Large Language Model focusing on chest X-ray radiology report **in Korean**
![Demo Image](demo.png)
## ğŸ’¡ Introduction
Ko-Radiology-GPTëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±ëœ í‰ë¶€ X-ì„  ë°©ì‚¬ì„  ë³´ê³ ì„œì— ì´ˆì ì„ ë§ì¶˜ ì‹¤ì‹œê°„ ì§ˆì˜ì‘ë‹µ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ì— ì˜ì–´ ê¸°ë°˜ì˜ ë°©ì‚¬ì„  íŒë…ë³´ê³ ì„œ ì±—ë´‡ [Hippo](https://github.com/healthhub-ai/SNU-Radiology-GPT/)ë¥¼ í•œêµ­ì–´ë¡œ í™•ì¥í•˜ê³  ê°œì„ í•œ ê²ƒìœ¼ë¡œ, ë³µì¡í•œ ì˜ë£Œ ìš©ì–´ì™€ ë°©ì‚¬ì„  íŒë… ê²°ê³¼ë¥¼ ì´í•´í•˜ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì‹ ì†í•˜ê²Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* Base Model: [Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)  
* Dataset: 
    - (translated) [MIMIC-CXR](https://physionet.org/content/mimic-cxr/2.0.0/): ì•½ 160kê°œì˜ ë…¸íŠ¸ë¥¼ Google Translateì„ í†µí•´ ë²ˆì—­í•˜ì—¬ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.  
    - [ì˜ë£Œ, ë²•ë¥  ì „ë¬¸ ì„œì  ë§ë­‰ì¹˜ ë°ì´í„°ì…‹](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=71487)
    - [ì „ë¬¸ë¶„ì•¼ í•œì˜ ë§ë­‰ì¹˜](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=111)
* Method: Instruction-following(by Stanford Alpaca) ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ ìƒì„±ì—ëŠ” GPT-3.5 turbo APIë¥¼ ì´ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.


## ğŸ’» Environment
ì œê³µë“œë¦° Dockerfileì„ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  

#### 1. Docker Image Build
```bash
docker build -t hippo:latest .
```

#### 2. Docker Run Container
```bash
docker run -v MOUNT_PATH:/workspace --gpus GPU_NUM -it --name "hippo" hippo:latest
```
-v ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•˜ì˜€ìŠµë‹ˆë‹¤. MOUNT_PATHëŠ” ì»¨í…Œì´ë„ˆì— ë§ˆìš´íŠ¸í•  ë¡œì»¬ ê²½ë¡œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.  
--gpus ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ ì‚¬ìš©í•  GPUë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
-it ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ í„°ë¯¸ë„ì„ ì´ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
"hippo"ëŠ” ì»¨í…Œì´ë„ˆì˜ ì´ë¦„, hippo:latestëŠ” ì´ë¯¸ì§€ ì´ë¦„ì…ë‹ˆë‹¤.  

3. Container ì¬ì‚¬ìš©  
ì‹¤í–‰ì¤‘ì¸ ì»¨í…Œì´ë„ˆì— ì¬ì§„ì…í•˜ì—¬ ì‘ì—…í•˜ëŠ” ê²½ìš°, ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
```bash
docker exec -it hippo /bin/bash
```
hippoëŠ” ì‹¤í–‰ì¤‘ì¸ ì»¨í…Œì´ë„ˆì˜ ì´ë¦„ì…ë‹ˆë‹¤.

### Requirements
ì´í›„ í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë¡œë“œí•˜ë©´ ë©ë‹ˆë‹¤.
```bash
bash setup.sh
```

## ğŸ“š Data Preprocessing
#### 1. MIMIC-CXR í•œêµ­ì–´ ë²ˆì—­

[MIMIC-CXR ì‚¬ì´íŠ¸](https://physionet.org/content/mimic-cxr/2.0.0/)ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë‹¤ìš´ë°›ì€ í›„, ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ë³´ì„¸ìš”.
```bash
python translate.py --input-path INPUT_PATH --output-path OUTPUT_PATH
```

#### 2. Data Preprocessing

ë²ˆì—­ëœ MIMIC-CXR ë°ì´í„° ë° AI hub ë°ì´í„°ë“¤ì˜ ì „ì²˜ë¦¬ ê³¼ì •ì…ë‹ˆë‹¤. 
`{id, note}` í˜•ì‹ì˜ csv ë°ì´í„°ë¥¼ `input/` ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ê³ , ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´, `output/` ë””ë ‰í† ë¦¬ì— ê²°ê³¼ê°€ ì €ì¥ë©ë‹ˆë‹¤. `API_KEY` ìë¦¬ì—ëŠ” OpenAIì—ì„œ ë°œê¸‰ë°›ì€ API Keyë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤. ê° ê³¼ì •ì˜ ë””í…Œì¼ì€ ì•„ë˜ Details of User Manualì„ ì°¸ê³ í•´ì£¼ì„¸ìš”!

```bash
bash preprocess.sh API_KEY
```  

## ğŸ”„ Fine-tuning Llama Model
ì´ í”„ë¡œì íŠ¸ëŠ” íŠ¹ì • ì‘ì—…ì„ ìœ„í•´ Llama ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ë˜ë©°, í›ˆë ¨ ê³¼ì •ì€ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ë¡œ ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë¨¼ì €, ì•„ë˜ ëª…ë ¹ì–´ë¡œ Huggingface-Cliì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
```bash
# huggingfaceì— ë¡œê·¸ì¸í•˜ì‹  í›„ í† í°ì„ ë°œê¸‰í•˜ì„¸ìš”. Y/n ì§ˆë¬¸ì—ëŠ” n ìœ¼ë¡œ ëŒ€ë‹µí•˜ë©´ ë©ë‹ˆë‹¤.
huggingface-cli login
```

ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ fine-tuningìœ¼ë¥´ í•˜ë©´ ë©ë‹ˆë‹¤. 
```bash
python "src/fine_tuning.py" \
--output_dir OUTPUT-DIR \
--model_name_or_path "meta-llama/Llama-2-7b-chat-hf" \
--data_path DATA-PATH \
--num_train_epochs 3 \
--per_device_train_batch_size 4 \
--per_device_eval_batch_size 4 \
--gradient_accumulation_steps 8 \
--evaluation_strategy "no" \
--save_strategy "epoch" \
--learning_rate 2e-4 \
--weight_decay 0.0 \
--warmup_ratio 0.03 \
--lr_scheduler_type "cosine" \
--logging_steps 1 \
--gradient_checkpointing True \
--ddp_timeout 1800
```
* OUTPUT-DIR: í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë  ê²½ë¡œì…ë‹ˆë‹¤. 
* DATA-PAT: ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì´ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ë¡œì…ë‹ˆë‹¤.
ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤ë„ í•„ìš”ì— ë”°ë¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ ëª…ë ¹ì–´ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.
```bash
# Example: with 006-Medical dataset
python "src/fine_tuning.py" \
--output_dir "./finetuned_model" \
--model_name_or_path "meta-llama/Llama-2-7b-chat-hf" \
--data_path "output/006-Medical_postprocess.jsonl" \
--num_train_epochs 3 \
--per_device_train_batch_size 4 \
--per_device_eval_batch_size 4 \
--gradient_accumulation_steps 8 \
--evaluation_strategy "no" \
--save_strategy "epoch" \
--learning_rate 2e-4 \
--weight_decay 0.0 \
--warmup_ratio 0.03 \
--lr_scheduler_type "cosine" \
--logging_steps 1 \
--gradient_checkpointing True \
--ddp_timeout 1800
```

## ğŸ¤– Inference
í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  

```bash
python src/inference.py --ft_path MODEL_PATH
```
* MODEL_PATH: í•™ìŠµëœ ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ” repositoryë¥¼ ì…ë ¥í•˜ì„¸ìš”.
í•´ë‹¹ ëª¨ë“ˆì—ì„œëŠ” í•™ìŠµëœ radiology_GPTê°€ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©ìì™€ ì§ˆì˜ì‘ë‹µì„ í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ì „ì— ì´ë£¨ì–´ì¡Œë˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤.  
* PreTrained ëª¨ë¸ì€ `h2a0e0u2n/changtongsul`ì—ì„œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¡œ pretrained modelì„ ì´ìš©í•´ë³´ì„¸ìš”!

```bash
# Example: pre-trained model
python src/inference.py --ft_path h2a0e0u2n/changtongsul
```

## ğŸŒ Demo
ì•„ë˜ ëª¨ë“ˆì—ì„œëŠ” ì‚¬ìš©ìê°€ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ Ko-Radiology-GPTë¥¼ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
DemoëŠ” Gradio ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. (Huggingface chat demo ì½”ë“œ ì°¸ì¡°)  
ëª…ë ¹ì–´ ì‹¤í–‰ í›„ í„°ë¯¸ë„ì— ì¶œë ¥ë˜ëŠ” public urlì„ í´ë¦­í•˜ì‹œë©´ Demoë¥¼ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
python src/app.py --model MODEL_PATH
```

* MODEL_PATH: í•™ìŠµëœ ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ” repositoryë¥¼ ì…ë ¥í•˜ì„¸ìš”. 
* Pretrainedëœ ëª¨ë¸ì„ ì´ìš©í•˜ê³  ì‹¶ë‹¤ë©´ `ko-gpt`ë¥¼ ì…ë ¥í•˜ì„¸ìš”. default ê°’ì€ ê¸°ì¡´ llama-2-7b-chat ëª¨ë¸ì…ë‹ˆë‹¤.

```bash
# Example: pre-trained model
python src/app.py --model ko-gpt
```


## ğŸ“Š Compare and Evaluate
### Comparison
ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ ë‹µë³€ì„ ë°›ì•„ ë³´ê³  ì‹¶ìœ¼ì‹¤ ê²½ìš°, Comparison ë””ë ‰í† ë¦¬ì— ìˆëŠ” ëª¨ë“ˆë“¤ì„ í™œìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  

#### 1. llama2.py
Fine-tuning ì „ Llama2 modelì˜ ë‹µë³€ì„ ë°›ì•„ì˜¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ë¼ë§ˆ2ì— ì „ì†¡í•  promptë¥¼ 'prompt'ë¼ëŠ” columnì— ë‹´ê³ ìˆëŠ” csv íŒŒì¼ì„ input_pathì— ëª…ì‹œí•´ì£¼ì‹œë©´, 'llama2_answer'ì´ë¼ëŠ” ìƒˆë¡œìš´ columnì— ë‹µë³€ì„ ì €ì¥í•˜ì—¬ ëª…ì‹œí•´ì£¼ì‹  save_pathì— csv íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

Llama2ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” huggingface CLI loginì´ í•„ìš”í•©ë‹ˆë‹¤. ì•ì„œ Fine Tuning ì„¹ì…˜ì—ì„œ ì„¤ëª…ë“œë¦° ë°©ë²•ëŒ€ë¡œ CLI loginì„ ì§„í–‰í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.
```bash
python comparison/llma2.py --input_path INPUT_PATH --save_path OUTPUT_PATH
```
* INPUT_PATH: path to csv input file
* OUTPUT_PATH: path to csv output file

#### 2. hippo.py
ì´ì „ í”„ë¡œì íŠ¸ì—ì„œ ê°œë°œí•œ ì˜ì–´ ì§ˆì˜ì‘ë‹µ ëª¨ë¸ì¸ hippoì˜ ë‹µë³€ì„ ë°›ì•„ì˜¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. Hippoì— ì „ì†¡í•  promptë¥¼ 'prompt'ë¼ëŠ” columnì— ë‹´ê³ ìˆëŠ” csv íŒŒì¼ì„ input_pathì— ëª…ì‹œí•´ì£¼ì‹œë©´, 'hippo_answer'ì´ë¼ëŠ” ìƒˆë¡œìš´ columnì— ë‹µë³€ì„ ì €ì¥í•˜ì—¬ ëª…ì‹œí•´ì£¼ì‹  save_pathì— csv íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
Base modelì„ Llama2ë¡œ í•˜ê³  ìˆê¸°ì—, ì—­ì‹œ huggingface CLI loginì´ í•„ìš”í•©ë‹ˆë‹¤. 
```bash
python comparison/hippo.py --input_path INPUT_PATH --save_path OUTPUT_PATH --hippo_model_dir MODEL_PATH
```
* INPUT_PATH: path to csv input file
* OUTPUT_PATH: path to csv output file
* MODEL_PATH: path to pretrained model 

#### 3. koGPT.py
ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ê°œë°œí•œ í•œêµ­ì–´ ì§ˆì˜ì‘ë‹µ ëª¨ë¸ì¸ Ko-Radiology-GPTì˜ ë‹µë³€ì„ ë°›ì•„ì˜¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. Ko-Radiology-GPTì— ì „ì†¡í•  promptë¥¼ 'prompt'ë¼ëŠ” columnì— ë‹´ê³ ìˆëŠ” csv íŒŒì¼ì„ input_pathì— ëª…ì‹œí•´ì£¼ì‹œë©´, 'koGPT_answer'ì´ë¼ëŠ” ìƒˆë¡œìš´ columnì— ë‹µë³€ì„ ì €ì¥í•˜ì—¬ ëª…ì‹œí•´ì£¼ì‹  save_pathì— csv íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
Base modelì„ Llama2ë¡œ í•˜ê³  ìˆê¸°ì—, ì—­ì‹œ huggingface CLI loginì´ í•„ìš”í•©ë‹ˆë‹¤. 
```bash
python comparison/koGPT.py --input_path INPUT_PATH --save_path OUTPUT_PATH --fine_tuned_model_dir MODEL_PATH
```

* INPUT_PATH: path to csv input file
* OUTPUT_PATH: path to csv output file
* MODEL_PATH: path to pretrained model 

### Evaluation
GPT-4ë¥¼ ì´ìš©í•˜ì—¬ í‰ê°€ê°€ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. í‰ê°€ ì§€í‘œëŠ” 1. Accuracy 2. Conciseness 3. Consistency 4. Understandabilityì˜ 4ê°€ì§€ê°€ ìˆìœ¼ë©°, ê° 1ì ë¶€í„° 4ì ê¹Œì§€ ì ìˆ˜ë¥¼ ë§¤ê²¨ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ë”ë¶ˆì–´ Ko-GPTì™€ ë‹¤ë¥¸ ì˜ì–´ ëª¨ë¸ì˜ ë‹µë³€ ìœ ì‚¬ë„ë¥¼ ë³´ê¸° ìœ„í•˜ì—¬ 5. Similarityë¥¼ ì¶”ê°€ë¡œ ì¸¡ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
GPT-4ë¡œë¶€í„° ê° ëª¨ë¸ì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ê²½ìš°, `evaluate.py`ë¥¼ ì´ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

ì•„ë˜ì˜ ëª¨ë“  ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” secrets.py íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹´ê³  ìˆìœ¼ë©°, evaluate_*.py íŒŒì¼ë“¤ê³¼ ë™ì¼í•œ directory hierarchyì— ìœ„ì¹˜ì‹œì¼œë‘ì‹œë©´ ë©ë‹ˆë‹¤.

```python
OPENAI_API_KEY = "your API key"  ## GPT4ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ OpenAI API key
```

ì´í›„ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ Evaluationì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```bash
python ./evaluate.py --input_path INPUT_PATH --output_path OUTPUT_PATH --type TYPE 
```
* INPUT_PATH: path to csv input file
* OUTPUT_PATH: path to csv output file
* TYPE: acc(accuracy), coc(conciseness), cos(consistency), und(underestandability), sim(similarity) ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.

## [Appendix] Details of User Manual
###  Data Preprocessing

Data Generationì€ ë‹¤ìŒì˜ ë‹¨ê³„ë¥¼ ê±°ì³ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.  

#### 0. (MIMIC-CXR data only) MIMIC-CXR ë°ì´í„°ì…‹ì—ì„œ ë°©ì‚¬ì„  íŒë…ë³´ê³ ì„œ íŒŒì¼ì¸ notesë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.  

ë³´ê³ ì„œë§ˆë‹¤ í˜•ì‹ì´ ì œê°ê°ì´ê¸° ë•Œë¬¸ì—, ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ”  **"EXAMINATION", "HISTORY", "INDICATION", "TECHNIQUE", "COMPARISON", "FINDINGS", "IMPRESSION"**  í•­ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

```bash
python preprocessing/preprocess_mimic_cxr.py --input_path INPUT_PATH --save_path SAVE_PATH
```
* INPUT_PATH: MIMIC-CXR notes ë°ì´í„°ì…‹ì´ ìœ„ì¹˜í•œ ê²½ë¡œì…ë‹ˆë‹¤.  
* SAVE_PATH: ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì´ ì €ì¥ë  ê²½ë¡œì…ë‹ˆë‹¤.


#### 1. Instruction generator
OpenAI APIë¥¼ ì´ìš©í•˜ì—¬ instructionì„ ìƒì„±í•©ë‹ˆë‹¤.  
```bash
python preprocessing/instruction_generator.py --input_path INPUT_PATH --save_path SAVE_PATH --api_key API_KEY
```  
ì´ ë•Œ max_requesets/token_per_minute, max_attemps ë“± API ì„¸ë¶€ ì„¤ì •ì„ ë³€ê²½í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì„¸ë¶€ íŒŒë¼ë¯¸í„°ëŠ” ì½”ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”!  
  
2. API Responseì—ì„œ ìƒì„±ëœ Instructionì„ í›„ì²˜ë¦¬í•˜ì—¬, ê° Instructionì— ëŒ€í•œ answerë¥¼ ìƒì„±í•˜ë„ë¡ ëª…ë ¹í•˜ëŠ” promptë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```bash
python preprocessing/postproc_question.py --input_path INPUT_PATH --save_path SAVE_PATH
```  
  
#### 3. Answer generator
OpenAI APIë¥¼ ë‹¤ì‹œ ì´ìš©í•˜ì—¬ í›„ì²˜ë¦¬í•œ ë°ì´í„°ì— ëŒ€í•œ Answerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
```bash
python preprocessing/answer_generator.py --input_path INPUT_PATH --save_path SAVE_PATH --api_key API_KEY
```  
#### 4. Instruction-Answer postprocess 
ìƒì„±í•œ Instruction-Answer ìŒì„ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.  
```bash
python preprocessing/answer_postprocess.py --input_path INPUT_PATH --save_path SAVE_PATH
```

#### 5. Convert to fine-tuning version
ë§ˆì§€ë§‰ìœ¼ë¡œ í›„ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ fine-tuningì„ ìœ„í•œ í˜•ì‹ìœ¼ë¡œ ê³ ì¹©ë‹ˆë‹¤.
```bash
python preprocessing/csv_to_jsonl_converter.py --input_path INPUT_PATH --save_path SAVE_PATH
```
ì, ì´ì œ `SAVE_PATH`ì—ëŠ” fine-tuningì„ ìœ„í•´ í•„ìš”í•œ ë°ì´í„°ì…‹ì´ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.

## Reference
[KAIST Asclepius](https://github.com/starmpcc/Asclepius)  
[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)  
[Open AI](https://github.com/openai/openai-cookbook/tree/main)  
[Huggingface Llama2 chat demo](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat/blob/main/app.py)  